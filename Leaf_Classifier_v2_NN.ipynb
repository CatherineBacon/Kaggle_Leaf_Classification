{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                species   margin1   margin2   margin3   margin4  \\\n",
      "0   1            Acer_Opalus  0.007812  0.023438  0.023438  0.003906   \n",
      "1   2  Pterocarya_Stenoptera  0.005859  0.000000  0.031250  0.015625   \n",
      "2   3   Quercus_Hartwissiana  0.005859  0.009766  0.019531  0.007812   \n",
      "3   5        Tilia_Tomentosa  0.000000  0.003906  0.023438  0.005859   \n",
      "4   6     Quercus_Variabilis  0.005859  0.003906  0.048828  0.009766   \n",
      "\n",
      "    margin5   margin6   margin7  margin8    ...      texture55  texture56  \\\n",
      "0  0.011719  0.009766  0.027344      0.0    ...       0.007812   0.000000   \n",
      "1  0.025391  0.001953  0.019531      0.0    ...       0.000977   0.000000   \n",
      "2  0.003906  0.005859  0.068359      0.0    ...       0.154300   0.000000   \n",
      "3  0.021484  0.019531  0.023438      0.0    ...       0.000000   0.000977   \n",
      "4  0.013672  0.015625  0.005859      0.0    ...       0.096680   0.000000   \n",
      "\n",
      "   texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
      "0   0.002930   0.002930   0.035156        0.0        0.0   0.004883   \n",
      "1   0.000000   0.000977   0.023438        0.0        0.0   0.000977   \n",
      "2   0.005859   0.000977   0.007812        0.0        0.0   0.000000   \n",
      "3   0.000000   0.000000   0.020508        0.0        0.0   0.017578   \n",
      "4   0.021484   0.000000   0.000000        0.0        0.0   0.000000   \n",
      "\n",
      "   texture63  texture64  \n",
      "0   0.000000   0.025391  \n",
      "1   0.039062   0.022461  \n",
      "2   0.020508   0.002930  \n",
      "3   0.000000   0.047852  \n",
      "4   0.000000   0.031250  \n",
      "\n",
      "[5 rows x 194 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "datafile = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "print(datafile.head())\n",
    "\n",
    "Y_train = datafile['species']\n",
    "X_train = datafile.drop('species', axis=1)\n",
    "\n",
    "# not looking at actual images for first pass, so drop id column from both test and train\n",
    "X_train = X_train.drop('id', axis=1)\n",
    "X_test = test.drop('id', axis=1)\n",
    "\n",
    "# one hot encode species\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 792 samples, validate on 198 samples\n",
      "Epoch 1/30\n",
      "792/792 [==============================] - 1s - loss: 4.5315 - acc: 0.0530 - val_loss: 4.4012 - val_acc: 0.0808\n",
      "Epoch 2/30\n",
      "792/792 [==============================] - 1s - loss: 3.8761 - acc: 0.1528 - val_loss: 3.6562 - val_acc: 0.1465\n",
      "Epoch 3/30\n",
      "792/792 [==============================] - 1s - loss: 2.9228 - acc: 0.2942 - val_loss: 2.8721 - val_acc: 0.1869\n",
      "Epoch 4/30\n",
      "792/792 [==============================] - 1s - loss: 2.2945 - acc: 0.3914 - val_loss: 2.1426 - val_acc: 0.4343\n",
      "Epoch 5/30\n",
      "792/792 [==============================] - 1s - loss: 1.7699 - acc: 0.5240 - val_loss: 1.7870 - val_acc: 0.4697\n",
      "Epoch 6/30\n",
      "792/792 [==============================] - 1s - loss: 1.4119 - acc: 0.6010 - val_loss: 1.3611 - val_acc: 0.6263\n",
      "Epoch 7/30\n",
      "792/792 [==============================] - 1s - loss: 1.1838 - acc: 0.6503 - val_loss: 1.1425 - val_acc: 0.6869\n",
      "Epoch 8/30\n",
      "792/792 [==============================] - 1s - loss: 0.9409 - acc: 0.7361 - val_loss: 0.9848 - val_acc: 0.6869\n",
      "Epoch 9/30\n",
      "792/792 [==============================] - 1s - loss: 0.8212 - acc: 0.7588 - val_loss: 0.7826 - val_acc: 0.7677\n",
      "Epoch 10/30\n",
      "792/792 [==============================] - 1s - loss: 0.6674 - acc: 0.7866 - val_loss: 0.6766 - val_acc: 0.8485\n",
      "Epoch 11/30\n",
      "792/792 [==============================] - 1s - loss: 0.5713 - acc: 0.8220 - val_loss: 0.6045 - val_acc: 0.7727\n",
      "Epoch 12/30\n",
      "792/792 [==============================] - 1s - loss: 0.4818 - acc: 0.8662 - val_loss: 0.5614 - val_acc: 0.8182\n",
      "Epoch 13/30\n",
      "792/792 [==============================] - 1s - loss: 0.4214 - acc: 0.8649 - val_loss: 0.4369 - val_acc: 0.8939\n",
      "Epoch 14/30\n",
      "792/792 [==============================] - 1s - loss: 0.3624 - acc: 0.8902 - val_loss: 0.4087 - val_acc: 0.8939\n",
      "Epoch 15/30\n",
      "792/792 [==============================] - 1s - loss: 0.3275 - acc: 0.9015 - val_loss: 0.4211 - val_acc: 0.8535\n",
      "Epoch 16/30\n",
      "792/792 [==============================] - 1s - loss: 0.2966 - acc: 0.9091 - val_loss: 0.3663 - val_acc: 0.8737\n",
      "Epoch 17/30\n",
      "792/792 [==============================] - 1s - loss: 0.2456 - acc: 0.9318 - val_loss: 0.2968 - val_acc: 0.9091\n",
      "Epoch 18/30\n",
      "792/792 [==============================] - 1s - loss: 0.2248 - acc: 0.9356 - val_loss: 0.3135 - val_acc: 0.9040\n",
      "Epoch 19/30\n",
      "792/792 [==============================] - 1s - loss: 0.1911 - acc: 0.9495 - val_loss: 0.3496 - val_acc: 0.8838\n",
      "Epoch 20/30\n",
      "792/792 [==============================] - 1s - loss: 0.1829 - acc: 0.9394 - val_loss: 0.2887 - val_acc: 0.8838\n",
      "Epoch 21/30\n",
      "792/792 [==============================] - 1s - loss: 0.1488 - acc: 0.9558 - val_loss: 0.2793 - val_acc: 0.9293\n",
      "Epoch 22/30\n",
      "792/792 [==============================] - 1s - loss: 0.1607 - acc: 0.9470 - val_loss: 0.3044 - val_acc: 0.9141\n",
      "Epoch 23/30\n",
      "792/792 [==============================] - 1s - loss: 0.1265 - acc: 0.9621 - val_loss: 0.2636 - val_acc: 0.9091\n",
      "Epoch 24/30\n",
      "792/792 [==============================] - 1s - loss: 0.1015 - acc: 0.9747 - val_loss: 0.2710 - val_acc: 0.9040\n",
      "Epoch 25/30\n",
      "792/792 [==============================] - 1s - loss: 0.0999 - acc: 0.9735 - val_loss: 0.2920 - val_acc: 0.9091\n",
      "Epoch 26/30\n",
      "792/792 [==============================] - 2s - loss: 0.0984 - acc: 0.9710 - val_loss: 0.2531 - val_acc: 0.9293\n",
      "Epoch 27/30\n",
      "792/792 [==============================] - 2s - loss: 0.1047 - acc: 0.9697 - val_loss: 0.2414 - val_acc: 0.9192\n",
      "Epoch 28/30\n",
      "792/792 [==============================] - 2s - loss: 0.0869 - acc: 0.9710 - val_loss: 0.1869 - val_acc: 0.9293\n",
      "Epoch 29/30\n",
      "792/792 [==============================] - 2s - loss: 0.0929 - acc: 0.9634 - val_loss: 0.2669 - val_acc: 0.9192\n",
      "Epoch 30/30\n",
      "792/792 [==============================] - 3s - loss: 0.0766 - acc: 0.9811 - val_loss: 0.2309 - val_acc: 0.9495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f57529f21d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(2000, input_dim=X_train.shape[1]),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2000),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(lb.classes_.size),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train.as_matrix(), \n",
    "    lb.transform(Y_train), \n",
    "    validation_split=0.2,\n",
    "    nb_epoch=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594/594 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_proba(X_test.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.93434432e-09,   5.51064348e-13,   3.80511898e-12, ...,\n",
       "          2.59748560e-08,   3.77012657e-11,   1.16432688e-12],\n",
       "       [  1.69020790e-13,   2.16540244e-10,   3.55619922e-10, ...,\n",
       "          1.08460590e-07,   8.19891775e-14,   2.25564605e-07],\n",
       "       [  2.22839294e-08,   9.65896547e-01,   5.56013333e-07, ...,\n",
       "          7.63894705e-16,   1.69151918e-15,   1.39521844e-05],\n",
       "       ..., \n",
       "       [  3.87928048e-06,   1.15771219e-10,   1.05911502e-10, ...,\n",
       "          1.66733713e-07,   1.03900536e-12,   8.56486281e-07],\n",
       "       [  7.97952676e-12,   7.67831632e-12,   5.98419283e-04, ...,\n",
       "          6.95353108e-10,   2.43126136e-12,   6.96372057e-11],\n",
       "       [  2.63293923e-23,   5.91441479e-12,   3.50027896e-09, ...,\n",
       "          3.19133001e-12,   8.75115054e-15,   3.22557160e-14]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = test['id']\n",
    "headers = lb.classes_.tolist()\n",
    "headers = ['id']+headers\n",
    "results = pd.DataFrame(data=predictions)\n",
    "labels = pd.DataFrame(labels)\n",
    "results = pd.concat([labels, results], axis=1)\n",
    "results.columns = headers"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
